{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Protocol\n",
    "\n",
    "import lancedb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.embeddings.sentence_transformers import SentenceTransformerEmbeddings\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# isort: off\n",
    "sys.path.append(\"..\")  # include repository-root to load modules from src folder\n",
    "from src.constants import LANCEDB_URI, post_path_json  # noqa: E402\n",
    "from src.embeddings import HuggingFaceEmbedder  # noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingFunction(Protocol):\n",
    "    \"\"\"\n",
    "    A protocol that represents a function for generating embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : List[str]\n",
    "        A list of strings for which embeddings are to be generated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[List[float]]\n",
    "        A list of embeddings, where each embedding is represented as\n",
    "        a list of floats.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, text: list[str]) -> list[list[float]]: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "post_path_json.is_dir()  # fails if it doesn't exist\n",
    "LANCEDB_URI.is_dir()  # fails if it doesn't exist\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "# - https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "emb_model_name = (\n",
    "    \"multi-qa-MiniLM-L6-cos-v1\"  # a pre-trained model of `sentence-transformers`\n",
    ")\n",
    "\n",
    "# secrets\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Embedding Models\n",
    "- Original Models : https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "> The `all-mpnet-base-v2` model provides the best quality, while `all-MiniLM-L6-v2` is 5 times faster and still offers good quality\n",
    "\n",
    "`multi-qa-MiniLM-L6-cos-v1`  (80MB) : \"tuned for semantic search: Given a query/question, it can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "test_docs = [\"Hello world\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model locally\n",
    "\n",
    "- big package: https://stackoverflow.com/questions/77205123/how-do-i-slim-down-sberts-sentencer-transformer-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings01 = model.encode(test_docs).tolist()\n",
    "# embeddings01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model from HuggingFace API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(model_name=model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow since it's an API call\n",
    "embeddings02 = embedder.embed(test_docs)\n",
    "# embeddings02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare embeddings\n",
    "(1 - np.array(embeddings01) / np.array(embeddings02)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LanceDB Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = get_registry().get(\"sentence-transformers\")\n",
    "model = model_registry.create(name=model_name)\n",
    "model.ndims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for ingestion (ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single JSON file\n",
    "\n",
    "\n",
    "def process_json_file(file_path: Path, emb_func: EmbeddingFunction) -> pd.DataFrame:\n",
    "    with open(file_path) as f:\n",
    "        data: dict = json.load(f)\n",
    "\n",
    "    # Extract the text data\n",
    "    paragraphs: list[str] = data.get(\"paragraphs\", [])\n",
    "    key_takeaways: list[str] = data.get(\"key_takeaways\", [])\n",
    "    combined_text: list[str] = paragraphs + key_takeaways\n",
    "\n",
    "    # Create embeddings for each text chunk\n",
    "    embeddings: list[list[float]] = emb_func(combined_text)\n",
    "\n",
    "    # Prepare a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"url\": [data.get(\"url\")] * len(combined_text),\n",
    "            \"title\": [data.get(\"title\")] * len(combined_text),\n",
    "            \"text\": combined_text,\n",
    "            \"embedding\": embeddings,\n",
    "            \"blog_tags\": [\" \".join(set(data.get(\"blog_tags\")))] * len(combined_text),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using local model\n",
    "emb_model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "def emb_func(text: list[str]) -> list[list[float]]:\n",
    "    return emb_model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all JSON files and process them\n",
    "files: list[Path] = list(post_path_json.glob(\"*.json\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for json_file in files[:1]:\n",
    "    df = process_json_file(file_path=json_file, emb_func=emb_func)\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context(\"display.max_colwidth\", None):\n",
    "#     display(df.iloc[[0]].style.set_properties(**{\"text-align\": \"left\"}))\n",
    "df.iloc[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data set to ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list of JSON files\n",
    "files: list[Path] = list(post_path_json.glob(\"*.json\"))\n",
    "print(f\"{len(files)} JSON files are in: {post_path_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table_data: list[dict[str, str]] = []\n",
    "\n",
    "for json_file in files[:2]:\n",
    "    with open(json_file) as f:\n",
    "        doc: dict = json.load(f)\n",
    "    paragraphs: list[str] = doc[\"paragraphs\"]\n",
    "    title: str = doc[\"title\"]\n",
    "    url: str = doc[\"url\"]\n",
    "    blog_tags: str = \" \".join(\n",
    "        set(doc[\"blog_tags\"])\n",
    "    )  # remove duplicates and join with space\n",
    "    test_table_data.extend(\n",
    "        [\n",
    "            {\"text\": para, \"title\": title, \"url\": url, \"blog_tags\": blog_tags}\n",
    "            for para in paragraphs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# print number of entries\n",
    "print(f\"{len(test_table_data)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 01 : Simple: just text + vector\n",
    "\n",
    "- following: \n",
    "    - https://lancedb.github.io/lancedb/embeddings/embedding_functions/\n",
    "    - https://lancedb.github.io/lancedb/embeddings/available_embedding_models/text_embedding_functions/sentence_transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding function\n",
    "emb_model: SentenceTransformerEmbeddings = (\n",
    "    get_registry().get(\"sentence-transformers\").create(name=emb_model_name)\n",
    ")\n",
    "n_dim_vec = emb_model.ndims()\n",
    "\n",
    "\n",
    "# Define the data model or schema\n",
    "class DataModel01(LanceModel):\n",
    "    vector: Vector(dim=n_dim_vec) = emb_model.VectorField()\n",
    "    text: str = emb_model.SourceField()\n",
    "    title: str\n",
    "    url: str\n",
    "    blog_tags: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/connect to the database\n",
    "db: lancedb.db.DBConnection = lancedb.connect(uri=LANCEDB_URI)\n",
    "\n",
    "# create table via schema, which creates embeddings for the text column stored in the vector column\n",
    "table01: lancedb.table.Table = db.create_table(\n",
    "    \"table01\", schema=DataModel01, mode=\"overwrite\"\n",
    ")\n",
    "\n",
    "# add data to the table, which creates embeddings for the text column stored in the vector column\n",
    "table01.add(data=test_table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing table content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test input\n",
    "table01.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test simple trivial query\n",
    "query = \"How to reduce Heart Disease Risk\"\n",
    "response: list[DataModel01] = table01.search(query).limit(5).to_pydantic(DataModel01)\n",
    "\n",
    "# unique URLs\n",
    "urls: set = {actual.url for actual in response}\n",
    "print(f\"{len(urls)} unique URL(s)\")\n",
    "\n",
    "# unique Titles\n",
    "titles: set = {actual.title for actual in response}\n",
    "print(f\"{len(titles)} unique Title(s)\")\n",
    "\n",
    "print(f\"{len(response)} results for: '{query}'\")\n",
    "for i, actual in enumerate(response):\n",
    "    print(f\"\\t{i}. {actual.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = table01.search(query).to_pydantic(DataModel01)\n",
    "print(f\"{len(response)} results for: {query}\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
