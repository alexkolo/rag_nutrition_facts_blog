{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the full RAG Flow\n",
    "\n",
    "## Flow\n",
    "\n",
    "1. Get user query\n",
    "2. Retrieve context from Knowledge Base based on query\n",
    "3. Create LLM prompt from query and context\n",
    "4. Send Prompt to LLM and get response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the external files every time before executing any cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from lancedb.table import Table\n",
    "\n",
    "from src.constants import REPO_PATH, get_rag_config\n",
    "from src.prompt_building import WELCOME_MSG, build_system_msg\n",
    "from src.retrieval import get_context, get_knowledge_base\n",
    "\n",
    "# ignore some warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secrets\n",
    "load_dotenv(REPO_PATH)\n",
    "groq_api_key = os.getenv(\"GROQ_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "### Indexes for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_base: Table = get_knowledge_base()\n",
    "print(f\"Number of entries in the table: {k_base.count_rows()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search index\n",
    "# k_base.create_fts_index([\"text\", \"title\", \"tags\"], replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector search index\n",
    "# (takes 30-60 seconds)\n",
    "# from constants import get_rag_config\n",
    "# device: str = get_rag_config()[\"embeddings\"][\"device\"]\n",
    "# k_base.create_index(metric=\"cosine\", replace=True, accelerator=\"cuda\" if device == \"cuda\" else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text: str = \"How can I reduce my heart Disease Risk?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve Context from Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the table\n",
    "retriever_config: dict = get_rag_config()[\"retriever\"]\n",
    "resp_formatted = get_context(k_base, query_text, **retriever_config)\n",
    "print(resp_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create LLM prompt from query and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = build_system_msg(context=resp_formatted)\n",
    "print(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES: list[dict[str, str]] = [\n",
    "    {\"role\": \"system\", \"content\": system_msg},\n",
    "    {\"role\": \"assistant\", \"content\": WELCOME_MSG.format(user_name=\"John Doe\")},\n",
    "    {\"role\": \"user\", \"content\": query_text},\n",
    "]\n",
    "for message in MESSAGES:\n",
    "    print(f\"{message['role'].upper()}: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Send Prompt to LLM and get response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groq API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_MODELS_URL: str = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "\n",
    "def get_model_list(api_key: str, models_url: str) -> list[dict]:\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url=models_url, headers=headers, timeout=5)\n",
    "    response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "    return response.json()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of models\n",
    "model_list: list[dict] = get_model_list(api_key=groq_api_key, models_url=GROQ_MODELS_URL)\n",
    "# get active models\n",
    "active_model_ids: list[str] = sorted([md[\"id\"] for md in model_list if md[\"active\"]])\n",
    "for model_id in active_model_ids:\n",
    "    print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=groq_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mixtral-8x7b-32768\",  # \"llama-3.1-70b-versatile\",  # \"llama3-70b-8192\",\n",
    "    messages=MESSAGES,\n",
    "    temperature=0.5,\n",
    "    stream=False,\n",
    ")\n",
    "dict(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
